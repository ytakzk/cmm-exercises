{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# models\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分類するクラス\n",
    "classes = ['normal','tumor'] \n",
    "nb_classes = len(classes)\n",
    "\n",
    "# 画像サイズ、batch数、epoch数\n",
    "img_width, img_height = 200, 200\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir      = 'dataset/train'\n",
    "validation_data_dir = 'dataset/validation'\n",
    "\n",
    "nb_train_samples      = 2000\n",
    "nb_validation_samples = 600\n",
    "\n",
    "result_dir = 'dataset/results'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "\n",
    "    input_tensor = Input(shape=(img_width, img_height, 3))\n",
    "    inception = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "    x = inception.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs=inception.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generator():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        zoom_range=0.0,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect')\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    return (train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:30: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:30: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=18.75, validation_data=<keras.pre..., epochs=20, callbacks=[<keras.ca..., steps_per_epoch=62.5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/62 [===========>..................] - ETA: 41s - loss: 1.8776 - acc: 0.5036"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint #重み保存の際、epochを通して最良の重みを保存するため\n",
    "import random\n",
    "\n",
    "for i in range(50, 60):\n",
    "\n",
    "    model = model_maker()\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "    checkpointer = ModelCheckpoint('ex1-v3/finetuning' + str(i) + '.h5', monitor='val_acc', verbose=1, save_best_only=True)    \n",
    "\n",
    "    batch_size = np.random.choice([16, 32, 64, 128])\n",
    "\n",
    "    # 多クラス分類を指定\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizers.Nadam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    # 画像のジェネレータ生成\n",
    "    train_generator, validation_generator = image_generator()\n",
    "\n",
    "    start = time.time()\n",
    "    # Fine-tuning\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = nb_train_samples/batch_size,\n",
    "        validation_steps = nb_validation_samples/batch_size,\n",
    "        nb_epoch = nb_epoch,\n",
    "        validation_data = validation_generator,\n",
    "        callbacks=[checkpointer])\n",
    "\n",
    "    model.save(\"ex1-v3/model\" + str(i) + \".h5\")\n",
    "    \n",
    "    print(i, batch_size, checkpointer.best)\n",
    "    f = open('result-v3.txt','a')\n",
    "    f.write(str(i) +  ',' + str(batch_size) + ',' + str(checkpointer.best) + ',nadam' + '\\n')\n",
    "    f.close()\n",
    "    model = None\n",
    "    process_time = (time.time() - start) / 60\n",
    "    print(u'学習終了。かかった時間は', process_time, u'分です。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "# lossのグラフ\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "# accuracyのグラフ\n",
    "plt.plot(range(nb_epoch), acc, marker='.', label='acc')\n",
    "plt.plot(range(nb_epoch), val_acc, marker='.', label='val_acc')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotlyを使用してプロットしてみる。\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "##データの元を作る,複数書きたい場合はこれを繰り返す\n",
    "trace  = go.Scatter(y = hist.history['val_acc'],\n",
    "                    x=np.arange(1,201) ,\n",
    "                    name = 'val_acc',\n",
    "                    mode = 'lines')\n",
    "trace1 = go.Scatter(y = hist.history['val_loss'],\n",
    "                    x=np.arange(1,201) ,\n",
    "                    name = 'val_loss',\n",
    "                    mode = 'lines')\n",
    "\n",
    "data = [trace,trace1]\n",
    "\n",
    "\n",
    "##データのレイアウトを決める\n",
    "layout = go.Layout(\n",
    "    title='Fine-Tuning cancer or normal',\n",
    "    legend={\"x\":0.8, \"y\":0.5},#legendそのままにしたいならshowlegend = True\n",
    "\n",
    "    xaxis={\"title\":\"epoch\"},#軸の最大値最小値を決めたいならここに\"range\": [最小値,最大値]のように記入\n",
    "    yaxis={\"title\":\"accuracy\"}\n",
    ")\n",
    "\n",
    "##データをプロット\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,show_link = False)#グラフ表示のExport to plotly を消すにはここにshow_link=Falseのように記入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スコア\n",
    "\n",
    "$0.9466667$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`InceptionV2`など別のモデルを試してみたが、ハイパーパラメータの調整がうまくいかず`VGG16`より高スコアを出せなかったため、`VGG16`を使って精度向上を図ることにした。\n",
    "\n",
    "課題で与えられた元々のモデルでもすでに9割以上の精度が出ているが、１エポック目でほぼ収束しているように見えたため、FC層を３層に増やすとともにオプティマイザーの学習率を小さくしてより細かに探索を行うようにした。  \n",
    "また、オプティマイザーは`Adam`に変更した。\n",
    "\n",
    "これにより、`50`エポック目かけて徐々に学習データに対する正答率が上がるようになった。\n",
    "\n",
    "\n",
    "バリデーションデータに対するスコアは3エポック目に対するものが最高となった。\n",
    "一方でこの時学習データに対するスコアは`0.6557`しかなく、エポックを重ねるごとに学習データに対する`loss`も`accuracy`も改善していったがバリデーションデータに対するスコアの改善は見られなかった。\n",
    "\n",
    "ただし、バリデーションデータに対するスコアはほぼ`0.93`を超えており、大きな過学習を起こしているわけではないため、比較的良いモデルになったのではないかと考える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer.best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
