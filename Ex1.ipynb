{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# models\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['normal','tumor'] \n",
    "nb_classes = len(classes)\n",
    "\n",
    "img_width, img_height = 200, 200\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir      = 'dataset/train'\n",
    "validation_data_dir = 'dataset/validation'\n",
    "\n",
    "nb_train_samples      = 2000\n",
    "nb_validation_samples = 600\n",
    "\n",
    "result_dir = 'dataset/results'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "\n",
    "    input_tensor = Input(shape=(img_width, img_height, 3))\n",
    "    inception = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "    x = inception.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs=inception.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generator():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        zoom_range=0.0,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect')\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    return (train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=18.75, callbacks=[<keras.ca..., steps_per_epoch=62.5, validation_data=<keras.pre..., verbose=0, epochs=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 32 0.926666667461\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "2 32 0.961666665872\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "3 32 0.943333333333\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "4 32 0.946666667461\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import random\n",
    "\n",
    "# Run only 5 loops to avoid memory leak\n",
    "for i in range(1, 5):\n",
    "\n",
    "    model = model_maker()\n",
    "\n",
    "    checkpointer = ModelCheckpoint('ex1-result/finetuning' + str(i) + '.h5', monitor='val_acc', verbose=0, save_best_only=True)    \n",
    "\n",
    "    batch_size = np.random.choice([16, 32, 64, 128])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    train_generator, validation_generator = image_generator()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = nb_train_samples/batch_size,\n",
    "        validation_steps = nb_validation_samples/batch_size,\n",
    "        nb_epoch = nb_epoch,\n",
    "        validation_data = validation_generator,\n",
    "        callbacks=[checkpointer],\n",
    "        verbose=0)\n",
    "\n",
    "    model.save(\"ex1-result/model\" + str(i) + \".h5\")\n",
    "    \n",
    "    print(i, batch_size, checkpointer.best)\n",
    "    f = open('ex1-result/result.txt','a')\n",
    "    f.write(str(i) +  ',' + str(batch_size) + ',' + str(checkpointer.best) + '\\n')\n",
    "    f.close()\n",
    "    model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 試行の中の最高のモデルを取得\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('ex1-result/model2.h5')\n",
    "model.load_weights('ex1-result/finetuning2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "accuracy: 0.961666665872\n"
     ]
    }
   ],
   "source": [
    "_, validation_generator = image_generator()\n",
    "loss, acc = model.evaluate_generator(validation_generator, steps=nb_validation_samples/batch_size)\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回の試行では最高スコアは0.9616でしたが、他の試行では0.971666665872のスコアを得ることができました。\n",
    "\n",
    "0,32,0.96  \n",
    "1,64,0.866666665872  \n",
    "2,16,0.956666666667  \n",
    "3,32,0.954999999205  \n",
    "4,32,**0.971666665872**  \n",
    "5,16,0.963333333333  \n",
    "6,4,0.916666666667  \n",
    "7,64,0.936666665872  \n",
    "8,16,0.955  \n",
    "9,32,0.948333334128  \n",
    "10,16,0.961666666667  \n",
    "11,4,0.5  \n",
    "12,4,0.955  \n",
    "13,16,0.963333333333  \n",
    "14,32,**0.971666666667**  \n",
    "15,16,0.956666666667\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
