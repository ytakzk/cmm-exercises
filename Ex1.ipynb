{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# models\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分類するクラス\n",
    "classes = ['normal','tumor'] \n",
    "nb_classes = len(classes)\n",
    "\n",
    "# 画像サイズ、batch数、epoch数\n",
    "img_width, img_height = 200, 200\n",
    "batch_size = 4\n",
    "nb_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir      = 'dataset/train'\n",
    "validation_data_dir = 'dataset/validation'\n",
    "\n",
    "nb_train_samples      = 2000\n",
    "nb_validation_samples = 600\n",
    "\n",
    "result_dir = 'dataset/results'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "\n",
    "    input_tensor = Input(shape=(img_width, img_height, 3))\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "    x = vgg16.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs=vgg16.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generator():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        zoom_range=0.4,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect')\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    return (train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 200, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 24,316,866\n",
      "Trainable params: 9,602,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデル作成\n",
    "model = model_maker()\n",
    "\n",
    "# 最後の6層以外の重みをfreeze\n",
    "for layer in model.layers[:len(model.layers) - 7]:\n",
    "    layer.trainable = False\n",
    "        \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint #重み保存の際、epochを通して最良の重みを保存するため\n",
    "\n",
    "# モデル重みデータの保存 (monitor: 監視する値, save_best_only=Trueの場合，監視しているデータの最良モデルが上書きされない)\n",
    "# 各epochで最良の重みが保存される\n",
    "checkpointer = ModelCheckpoint('ex1/finetuning3.h5', monitor='val_acc', verbose=1, save_best_only=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:17: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:17: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., callbacks=[<keras.ca..., validation_data=<keras.pre..., steps_per_epoch=500.0, epochs=200, validation_steps=150.0)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6534 - acc: 0.6678- ETA: 4s - ETA: 1s - loss: 0.661Epoch 00001: val_acc improved from -inf to 0.89833, saving model to ex1/finetuning3.h5\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.6524 - acc: 0.6685 - val_loss: 0.2771 - val_acc: 0.8983\n",
      "Epoch 2/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.3209 - acc: 0.8657Epoch 00002: val_acc improved from 0.89833 to 0.91167, saving model to ex1/finetuning3.h5\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.3205 - acc: 0.8660 - val_loss: 0.2152 - val_acc: 0.9117\n",
      "Epoch 3/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1914 - acc: 0.9369- ETA: 0s - loss: 0.1921 - acc: 0.9Epoch 00003: val_acc improved from 0.91167 to 0.94167, saving model to ex1/finetuning3.h5\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.1913 - acc: 0.9370 - val_loss: 0.2116 - val_acc: 0.9417\n",
      "Epoch 4/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1662 - acc: 0.9419Epoch 00004: val_acc did not improve\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.1660 - acc: 0.9420 - val_loss: 0.3058 - val_acc: 0.8900\n",
      "Epoch 5/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9564- ETA: 1s - loss: 0.1315 Epoch 00005: val_acc did not improve\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.1345 - acc: 0.9565 - val_loss: 0.2163 - val_acc: 0.9417\n",
      "Epoch 6/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9634Epoch 00006: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.1328 - acc: 0.9635 - val_loss: 0.2892 - val_acc: 0.9067\n",
      "Epoch 7/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9609Epoch 00007: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.1144 - acc: 0.9610 - val_loss: 0.2429 - val_acc: 0.9117\n",
      "Epoch 8/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9664- ETA: 3s - loss: 0.1224 - acc:  - ETA: 3Epoch 00008: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.1160 - acc: 0.9665 - val_loss: 0.2717 - val_acc: 0.9200\n",
      "Epoch 9/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9684Epoch 00009: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.1105 - acc: 0.9685 - val_loss: 0.2465 - val_acc: 0.9300\n",
      "Epoch 10/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9729Epoch 00010: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0973 - acc: 0.9730 - val_loss: 0.3125 - val_acc: 0.8983\n",
      "Epoch 11/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9770Epoch 00011: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0969 - acc: 0.9770 - val_loss: 0.3093 - val_acc: 0.9050\n",
      "Epoch 12/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9704Epoch 00012: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0874 - acc: 0.9705 - val_loss: 0.3140 - val_acc: 0.9317\n",
      "Epoch 13/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9775- ETA: 1s - loss: 0.0776 - aEpoch 00013: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0791 - acc: 0.9775 - val_loss: 0.3827 - val_acc: 0.8733\n",
      "Epoch 14/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9749Epoch 00014: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0926 - acc: 0.9750 - val_loss: 0.2926 - val_acc: 0.8967\n",
      "Epoch 15/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9765Epoch 00015: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0875 - acc: 0.9765 - val_loss: 0.3624 - val_acc: 0.8917\n",
      "Epoch 16/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9760- ETA: 1s - loss: 0.09Epoch 00016: val_acc did not improve\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0950 - acc: 0.9755 - val_loss: 0.2585 - val_acc: 0.9167\n",
      "Epoch 17/200\n",
      "175/500 [=========>....................] - ETA: 32s - loss: 0.0885 - acc: 0.9757"
     ]
    }
   ],
   "source": [
    "# 多クラス分類を指定\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# 画像のジェネレータ生成\n",
    "train_generator, validation_generator = image_generator()\n",
    " \n",
    "start = time.time()\n",
    "# Fine-tuning\n",
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples/batch_size,\n",
    "    validation_steps = nb_validation_samples/batch_size,\n",
    "    nb_epoch = nb_epoch,\n",
    "    validation_data = validation_generator,\n",
    "    callbacks=[checkpointer])\n",
    "\n",
    "model_json_str = model.save(\"ex1/model3.h5\")\n",
    "\n",
    "process_time = (time.time() - start) / 60\n",
    "print(u'学習終了。かかった時間は', process_time, u'分です。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json_str = model.save(\"ex1/model3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "# lossのグラフ\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "# accuracyのグラフ\n",
    "plt.plot(range(nb_epoch), acc, marker='.', label='acc')\n",
    "plt.plot(range(nb_epoch), val_acc, marker='.', label='val_acc')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotlyを使用してプロットしてみる。\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "##データの元を作る,複数書きたい場合はこれを繰り返す\n",
    "trace  = go.Scatter(y = hist.history['val_acc'],\n",
    "                    x=np.arange(1,201) ,\n",
    "                    name = 'val_acc',\n",
    "                    mode = 'lines')\n",
    "trace1 = go.Scatter(y = hist.history['val_loss'],\n",
    "                    x=np.arange(1,201) ,\n",
    "                    name = 'val_loss',\n",
    "                    mode = 'lines')\n",
    "\n",
    "data = [trace,trace1]\n",
    "\n",
    "\n",
    "##データのレイアウトを決める\n",
    "layout = go.Layout(\n",
    "    title='Fine-Tuning cancer or normal',\n",
    "    legend={\"x\":0.8, \"y\":0.5},#legendそのままにしたいならshowlegend = True\n",
    "\n",
    "    xaxis={\"title\":\"epoch\"},#軸の最大値最小値を決めたいならここに\"range\": [最小値,最大値]のように記入\n",
    "    yaxis={\"title\":\"accuracy\"}\n",
    ")\n",
    "\n",
    "##データをプロット\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,show_link = False)#グラフ表示のExport to plotly を消すにはここにshow_link=Falseのように記入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スコア\n",
    "\n",
    "$0.9466667$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`InceptionV2`など別のモデルを試してみたが、ハイパーパラメータの調整がうまくいかず`VGG16`より高スコアを出せなかったため、`VGG16`を使って精度向上を図ることにした。\n",
    "\n",
    "課題で与えられた元々のモデルでもすでに9割以上の精度が出ているが、１エポック目でほぼ収束しているように見えたため、FC層を３層に増やすとともにオプティマイザーの学習率を小さくしてより細かに探索を行うようにした。  \n",
    "また、オプティマイザーは`Adam`に変更した。\n",
    "\n",
    "これにより、`50`エポック目かけて徐々に学習データに対する正答率が上がるようになった。\n",
    "\n",
    "\n",
    "バリデーションデータに対するスコアは3エポック目に対するものが最高となった。\n",
    "一方でこの時学習データに対するスコアは`0.6557`しかなく、エポックを重ねるごとに学習データに対する`loss`も`accuracy`も改善していったがバリデーションデータに対するスコアの改善は見られなかった。\n",
    "\n",
    "ただし、バリデーションデータに対するスコアはほぼ`0.93`を超えており、大きな過学習を起こしているわけではないため、比較的良いモデルになったのではないかと考える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
